{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you get an \"xcrun\" error, you will need to first:**\n",
    "    !xcode-select --install\n",
    "(It took about 3 minutes to install/update the Xcode Toolkit on my machine.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !xcode-select --install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 19.0.1, however version 20.2b1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wrapt\n",
      "\u001b[31mthinc 6.12.0 has requirement wrapt<1.11.0,>=1.10.0, but you'll have wrapt 1.12.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: wrapt\n",
      "Successfully installed wrapt-1.12.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting setuptools\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/95/f657b6e17f00c3f35b5f68b10e46c3a43af353d8856bd57bfcfb1dbb3e92/setuptools-47.1.1-py3-none-any.whl (583kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 18.1MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: setuptools\n",
      "Successfully installed setuptools-47.1.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# I also had to update the following packages to install Tf 2.1 :\n",
    "# wrapt, setuptools\n",
    "\n",
    "!pip install wrapt --upgrade --ignore-installed\n",
    "!pip install setuptools --upgrade --ignore-installed\n",
    "\n",
    "# or\n",
    "#!conda update wrapt\n",
    "#!conda update setuptools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 19.0.1, however version 20.2b1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow==2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tharsen/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 3.72 s, total: 13.9 s\n",
      "Wall time: 8.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we go\n",
    "\n",
    "## Part 1 : GPT-2 \"Greedy Search\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
      "\n",
      "I'm not sure if I'll\n",
      "CPU times: user 8.49 s, sys: 3.15 s, total: 11.6 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# set input phrase\n",
    "input_phrase = 'I enjoy walking with my cute dog'\n",
    "#input_phrase = 'I love my mother' \n",
    "#input_phrase = 'I love cake'\n",
    "\n",
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode(input_phrase, return_tensors='tf')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : GPT-2 \"Beam Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I'm not sure if I'll ever be able to walk with him again. I'm not sure if I'll\n"
     ]
    }
   ],
   "source": [
    "# activate beam search and early_stopping\n",
    "beam_output = model.generate(\n",
    "    input_ids,  \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(beam_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
      "1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
      "2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
      "3: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
      "4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
      "\n",
      "I've been thinking about this for a while now, and I think it's time for me to take a step\n"
     ]
    }
   ],
   "source": [
    "# set return_num_sequences > 1\n",
    "beam_outputs = model.generate(\n",
    "    input_ids, \n",
    "    max_length=50, \n",
    "    num_beams=5, \n",
    "    no_repeat_ngram_size=2, \n",
    "    num_return_sequences=5, \n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "# now we have 3 output sequences\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, beam_output in enumerate(beam_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog. He just gave me a whole new hand sense.\"\n",
      "\n",
      "But it seems that the dogs have learned a lot from teasing at the local batte harness once they take on the outside.\n",
      "\n",
      "\"I take\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I don't like to be at home too much. I also find it a bit weird when I'm out shopping. I am always away from my house a lot, but I do have a few friends\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# use temperature to decrease the sensitivity to low probability candidates\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=0, \n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-K Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog. It's so good to have an environment where your dog is available to share with you and we'll be taking care of you.\n",
      "\n",
      "We hope you'll find this story interesting!\n",
      "\n",
      "I am from\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# set top_k to 50\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-P Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog. He will never be the same. I watch him play.\n",
      "\n",
      "\n",
      "Guys, my dog needs a name. Especially if he is found with wings.\n",
      "\n",
      "\n",
      "What was that? I had a lot of\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# deactivate top_k sampling and sample only from 92% most likely words\n",
    "sample_output = model.generate(\n",
    "    input_ids, \n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(sample_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: I enjoy walking with my cute dog. It's so good to have the chance to walk with a dog. But I have this problem with the dog and how he's always looking at us and always trying to make me see that I can do something\n",
      "1: I enjoy walking with my cute dog. I like seeing him, I don't like having my dog go through me, but when we walk together that makes for a wonderful bonding moment. I appreciate the interaction, I just don't understand how it would\n",
      "2: I enjoy walking with my cute dog and playing with our kids,\" said David J. Smith, director of the Humane Society of the US.\n",
      "\n",
      "\"So as a result, I've got more work in my time,\" he said.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set seed to reproduce results. Feel free to change the seed though to get different results\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
